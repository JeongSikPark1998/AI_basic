{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[6]CNN(TransferLearning).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CNN(image classification)\n",
        "###CIFAR-10 dataset\n",
        "###transfer learning 중 ResNet50을 이용 (higher accuracy)"
      ],
      "metadata": {
        "id": "tWcjBhtKeLLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "\n",
        "print(\"tensorflow version: \", tf.__version__)\n",
        "print(\"python version: \", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPoFngq6B9Zi",
        "outputId": "2fbd82ed-0b87-466e-8a23-fad5be789fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version:  2.8.0\n",
            "python version:  3.7.13 (default, Mar 16 2022, 17:37:17) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
        "\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "#x_train, _, y_train,_ = train_test_split(x_train, y_train, test_size=0.5, random_state=42)\n",
        "x_val, _, y_val,_ = train_test_split(x_test, y_test, test_size=0.8, random_state=42)\n",
        "\n",
        "input_shape = x_train.shape[1:]"
      ],
      "metadata": {
        "id": "Q3zdx7yiB9bH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_epoch = 80\n",
        "g_batch = 128\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"reduced train/val size:\", len(x_train), len(x_val), \"input shape:\", input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZlDb94rB9cX",
        "outputId": "2bf7772e-81b7-4cd7-ff1c-09774d30034d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reduced train/val size: 50000 2000 input shape: (32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Conv2D\n",
        "\n",
        "#C-P-drop-C-P-drop-C-C-P-fc-drop-fc\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(128,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Dropout(0.25))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(Conv2D(256,(3,3),activation='relu', padding='same'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(1000,activation='relu'))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "38CgpWbkB9e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "cnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r12U9oh-B9gJ",
        "outputId": "0a9132cd-b558-4a2d-d4c8-dcc9396dd20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              2305000   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,275,906\n",
            "Trainable params: 3,275,906\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist=cnn.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "g_org_res=cnn.evaluate(x_test,y_test,verbose=0)\n",
        "print(\"Baseline 정확률은\",g_org_res[1]*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ht0g8G7B9g9",
        "outputId": "41a74f8e-feb9-49e2-fadd-f90031f7f823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "391/391 [==============================] - 25s 37ms/step - loss: 2.1614 - accuracy: 0.1945 - val_loss: 1.9960 - val_accuracy: 0.3090\n",
            "Epoch 2/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.8846 - accuracy: 0.3169 - val_loss: 1.9117 - val_accuracy: 0.3065\n",
            "Epoch 3/80\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 1.7587 - accuracy: 0.3624 - val_loss: 1.7948 - val_accuracy: 0.3505\n",
            "Epoch 4/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.6826 - accuracy: 0.3897 - val_loss: 1.7720 - val_accuracy: 0.3680\n",
            "Epoch 5/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.6174 - accuracy: 0.4133 - val_loss: 1.6559 - val_accuracy: 0.4080\n",
            "Epoch 6/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.5661 - accuracy: 0.4326 - val_loss: 1.7067 - val_accuracy: 0.4010\n",
            "Epoch 7/80\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 1.5236 - accuracy: 0.4477 - val_loss: 1.5848 - val_accuracy: 0.4330\n",
            "Epoch 8/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.4871 - accuracy: 0.4616 - val_loss: 1.5329 - val_accuracy: 0.4590\n",
            "Epoch 9/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.4564 - accuracy: 0.4761 - val_loss: 1.4878 - val_accuracy: 0.4700\n",
            "Epoch 10/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.4277 - accuracy: 0.4860 - val_loss: 1.4322 - val_accuracy: 0.4995\n",
            "Epoch 11/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.4043 - accuracy: 0.4964 - val_loss: 1.4331 - val_accuracy: 0.4955\n",
            "Epoch 12/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.3824 - accuracy: 0.5033 - val_loss: 1.4034 - val_accuracy: 0.5085\n",
            "Epoch 13/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.3609 - accuracy: 0.5125 - val_loss: 1.3978 - val_accuracy: 0.5120\n",
            "Epoch 14/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.3398 - accuracy: 0.5208 - val_loss: 1.3801 - val_accuracy: 0.5220\n",
            "Epoch 15/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.3212 - accuracy: 0.5299 - val_loss: 1.3434 - val_accuracy: 0.5345\n",
            "Epoch 16/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.2975 - accuracy: 0.5415 - val_loss: 1.3191 - val_accuracy: 0.5420\n",
            "Epoch 17/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.2865 - accuracy: 0.5414 - val_loss: 1.3166 - val_accuracy: 0.5415\n",
            "Epoch 18/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.2683 - accuracy: 0.5504 - val_loss: 1.2533 - val_accuracy: 0.5620\n",
            "Epoch 19/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.2532 - accuracy: 0.5556 - val_loss: 1.2599 - val_accuracy: 0.5595\n",
            "Epoch 20/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.2375 - accuracy: 0.5649 - val_loss: 1.2567 - val_accuracy: 0.5630\n",
            "Epoch 21/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.2227 - accuracy: 0.5689 - val_loss: 1.2379 - val_accuracy: 0.5725\n",
            "Epoch 22/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.2095 - accuracy: 0.5732 - val_loss: 1.2517 - val_accuracy: 0.5615\n",
            "Epoch 23/80\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 1.1954 - accuracy: 0.5779 - val_loss: 1.2271 - val_accuracy: 0.5700\n",
            "Epoch 24/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.1844 - accuracy: 0.5816 - val_loss: 1.1903 - val_accuracy: 0.5875\n",
            "Epoch 25/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.1694 - accuracy: 0.5894 - val_loss: 1.1940 - val_accuracy: 0.5885\n",
            "Epoch 26/80\n",
            "391/391 [==============================] - 14s 37ms/step - loss: 1.1563 - accuracy: 0.5945 - val_loss: 1.1765 - val_accuracy: 0.5880\n",
            "Epoch 27/80\n",
            "391/391 [==============================] - 15s 37ms/step - loss: 1.1470 - accuracy: 0.5967 - val_loss: 1.1635 - val_accuracy: 0.6000\n",
            "Epoch 28/80\n",
            "391/391 [==============================] - 15s 38ms/step - loss: 1.1331 - accuracy: 0.6007 - val_loss: 1.1389 - val_accuracy: 0.6005\n",
            "Epoch 29/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.1216 - accuracy: 0.6063 - val_loss: 1.1312 - val_accuracy: 0.6045\n",
            "Epoch 30/80\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 1.1120 - accuracy: 0.6103 - val_loss: 1.1264 - val_accuracy: 0.6120\n",
            "Epoch 31/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.1005 - accuracy: 0.6130 - val_loss: 1.1130 - val_accuracy: 0.6115\n",
            "Epoch 32/80\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 1.0905 - accuracy: 0.6156 - val_loss: 1.0998 - val_accuracy: 0.6175\n",
            "Epoch 33/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0825 - accuracy: 0.6207 - val_loss: 1.0977 - val_accuracy: 0.6185\n",
            "Epoch 34/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0716 - accuracy: 0.6243 - val_loss: 1.1156 - val_accuracy: 0.6070\n",
            "Epoch 35/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0597 - accuracy: 0.6303 - val_loss: 1.0910 - val_accuracy: 0.6250\n",
            "Epoch 36/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0504 - accuracy: 0.6336 - val_loss: 1.1018 - val_accuracy: 0.6110\n",
            "Epoch 37/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0400 - accuracy: 0.6361 - val_loss: 1.0523 - val_accuracy: 0.6335\n",
            "Epoch 38/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0336 - accuracy: 0.6377 - val_loss: 1.0591 - val_accuracy: 0.6310\n",
            "Epoch 39/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0239 - accuracy: 0.6422 - val_loss: 1.0432 - val_accuracy: 0.6385\n",
            "Epoch 40/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0145 - accuracy: 0.6449 - val_loss: 1.0452 - val_accuracy: 0.6310\n",
            "Epoch 41/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 1.0031 - accuracy: 0.6490 - val_loss: 1.0465 - val_accuracy: 0.6305\n",
            "Epoch 42/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9972 - accuracy: 0.6507 - val_loss: 1.0369 - val_accuracy: 0.6465\n",
            "Epoch 43/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9878 - accuracy: 0.6576 - val_loss: 1.0103 - val_accuracy: 0.6490\n",
            "Epoch 44/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9759 - accuracy: 0.6596 - val_loss: 1.0126 - val_accuracy: 0.6375\n",
            "Epoch 45/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9685 - accuracy: 0.6605 - val_loss: 0.9974 - val_accuracy: 0.6460\n",
            "Epoch 46/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9592 - accuracy: 0.6647 - val_loss: 1.0241 - val_accuracy: 0.6355\n",
            "Epoch 47/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9528 - accuracy: 0.6660 - val_loss: 0.9858 - val_accuracy: 0.6500\n",
            "Epoch 48/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9459 - accuracy: 0.6703 - val_loss: 0.9853 - val_accuracy: 0.6540\n",
            "Epoch 49/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9366 - accuracy: 0.6741 - val_loss: 1.0030 - val_accuracy: 0.6430\n",
            "Epoch 50/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9300 - accuracy: 0.6761 - val_loss: 0.9691 - val_accuracy: 0.6520\n",
            "Epoch 51/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9194 - accuracy: 0.6797 - val_loss: 0.9824 - val_accuracy: 0.6515\n",
            "Epoch 52/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9122 - accuracy: 0.6827 - val_loss: 0.9796 - val_accuracy: 0.6545\n",
            "Epoch 53/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.9062 - accuracy: 0.6847 - val_loss: 0.9558 - val_accuracy: 0.6605\n",
            "Epoch 54/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8967 - accuracy: 0.6898 - val_loss: 0.9471 - val_accuracy: 0.6650\n",
            "Epoch 55/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8880 - accuracy: 0.6935 - val_loss: 0.9407 - val_accuracy: 0.6665\n",
            "Epoch 56/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8828 - accuracy: 0.6941 - val_loss: 0.9354 - val_accuracy: 0.6665\n",
            "Epoch 57/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8731 - accuracy: 0.6956 - val_loss: 0.9555 - val_accuracy: 0.6650\n",
            "Epoch 58/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8696 - accuracy: 0.6963 - val_loss: 0.9224 - val_accuracy: 0.6755\n",
            "Epoch 59/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8595 - accuracy: 0.7018 - val_loss: 0.9278 - val_accuracy: 0.6715\n",
            "Epoch 60/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8529 - accuracy: 0.7038 - val_loss: 0.9202 - val_accuracy: 0.6780\n",
            "Epoch 61/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8485 - accuracy: 0.7036 - val_loss: 0.9131 - val_accuracy: 0.6800\n",
            "Epoch 62/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8367 - accuracy: 0.7087 - val_loss: 0.9088 - val_accuracy: 0.6820\n",
            "Epoch 63/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8312 - accuracy: 0.7120 - val_loss: 0.9144 - val_accuracy: 0.6825\n",
            "Epoch 64/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8242 - accuracy: 0.7123 - val_loss: 0.8848 - val_accuracy: 0.6920\n",
            "Epoch 65/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8185 - accuracy: 0.7165 - val_loss: 0.8796 - val_accuracy: 0.6890\n",
            "Epoch 66/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8127 - accuracy: 0.7184 - val_loss: 0.8916 - val_accuracy: 0.6865\n",
            "Epoch 67/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.8031 - accuracy: 0.7211 - val_loss: 0.8752 - val_accuracy: 0.6845\n",
            "Epoch 68/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7973 - accuracy: 0.7228 - val_loss: 0.9079 - val_accuracy: 0.6820\n",
            "Epoch 69/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7941 - accuracy: 0.7255 - val_loss: 0.8876 - val_accuracy: 0.6920\n",
            "Epoch 70/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7830 - accuracy: 0.7302 - val_loss: 0.8821 - val_accuracy: 0.6955\n",
            "Epoch 71/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7795 - accuracy: 0.7269 - val_loss: 0.8915 - val_accuracy: 0.6875\n",
            "Epoch 72/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7701 - accuracy: 0.7330 - val_loss: 0.8546 - val_accuracy: 0.7000\n",
            "Epoch 73/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7671 - accuracy: 0.7313 - val_loss: 0.8527 - val_accuracy: 0.7065\n",
            "Epoch 74/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7592 - accuracy: 0.7377 - val_loss: 0.8483 - val_accuracy: 0.7035\n",
            "Epoch 75/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7527 - accuracy: 0.7361 - val_loss: 0.8520 - val_accuracy: 0.7015\n",
            "Epoch 76/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7498 - accuracy: 0.7392 - val_loss: 0.8470 - val_accuracy: 0.6995\n",
            "Epoch 77/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7437 - accuracy: 0.7415 - val_loss: 0.8345 - val_accuracy: 0.7110\n",
            "Epoch 78/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7362 - accuracy: 0.7458 - val_loss: 0.8329 - val_accuracy: 0.7060\n",
            "Epoch 79/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7323 - accuracy: 0.7456 - val_loss: 0.8396 - val_accuracy: 0.7000\n",
            "Epoch 80/80\n",
            "391/391 [==============================] - 14s 35ms/step - loss: 0.7244 - accuracy: 0.7488 - val_loss: 0.8345 - val_accuracy: 0.7080\n",
            "Baseline 정확률은 71.92000150680542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_class = 10 #number of class\n",
        "\n",
        "# for transfer learning only. using ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "# for transfer learning only\n",
        "transfermodel = ResNet50(weights='imagenet',include_top=False,\n",
        "                    input_shape=input_shape)\n",
        "#base_model.trainable=False     # it's up to you"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOqvDMpoB9kd",
        "outputId": "8e29a05a-3775-4c9f-c621-7c49879aa7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your model architecture\n",
        "model=Sequential()\n",
        "model.add(transfermodel)    # for transfer learning only\n",
        "model.add(Flatten())        # for transfer learning only\n",
        "model.add(Dense(1000,activation='relu'))\n",
        "model.add(Dense(no_class, activation='softmax'))"
      ],
      "metadata": {
        "id": "3Zx2it2ACj-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(0.00002),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKTOhla3Cj_T",
        "outputId": "e528d1b9-afb2-4b74-b6ec-11ba449de32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 1, 1, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              2049000   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,646,722\n",
            "Trainable params: 25,593,602\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist=model.fit(x_train, y_train, batch_size=g_batch, epochs=g_epoch,\n",
        "             validation_data=(x_val,y_val), verbose=1)\n",
        "\n",
        "yours=model.evaluate(x_test,y_test,verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WTC23VkCkAe",
        "outputId": "1901d762-72a8-4ae7-ea19-5cd02daf7aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "391/391 [==============================] - 70s 155ms/step - loss: 1.8932 - accuracy: 0.3740 - val_loss: 73.0072 - val_accuracy: 0.0905\n",
            "Epoch 2/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 1.1268 - accuracy: 0.6094 - val_loss: 3.0514 - val_accuracy: 0.1840\n",
            "Epoch 3/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.8414 - accuracy: 0.7068 - val_loss: 1.1205 - val_accuracy: 0.6225\n",
            "Epoch 4/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.6542 - accuracy: 0.7751 - val_loss: 1.0823 - val_accuracy: 0.6480\n",
            "Epoch 5/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.4989 - accuracy: 0.8327 - val_loss: 1.0750 - val_accuracy: 0.6635\n",
            "Epoch 6/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.3817 - accuracy: 0.8765 - val_loss: 1.0842 - val_accuracy: 0.6645\n",
            "Epoch 7/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.2848 - accuracy: 0.9121 - val_loss: 1.1055 - val_accuracy: 0.6680\n",
            "Epoch 8/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.2091 - accuracy: 0.9402 - val_loss: 1.1258 - val_accuracy: 0.6745\n",
            "Epoch 9/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.1576 - accuracy: 0.9563 - val_loss: 1.1832 - val_accuracy: 0.6765\n",
            "Epoch 10/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.1212 - accuracy: 0.9673 - val_loss: 1.2362 - val_accuracy: 0.6715\n",
            "Epoch 11/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0931 - accuracy: 0.9757 - val_loss: 1.2429 - val_accuracy: 0.6875\n",
            "Epoch 12/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0739 - accuracy: 0.9806 - val_loss: 1.2619 - val_accuracy: 0.6885\n",
            "Epoch 13/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0580 - accuracy: 0.9851 - val_loss: 1.3129 - val_accuracy: 0.6865\n",
            "Epoch 14/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0534 - accuracy: 0.9854 - val_loss: 1.3599 - val_accuracy: 0.6930\n",
            "Epoch 15/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0460 - accuracy: 0.9878 - val_loss: 1.3766 - val_accuracy: 0.6905\n",
            "Epoch 16/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0399 - accuracy: 0.9894 - val_loss: 1.4035 - val_accuracy: 0.6935\n",
            "Epoch 17/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0375 - accuracy: 0.9895 - val_loss: 1.4722 - val_accuracy: 0.6910\n",
            "Epoch 18/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0354 - accuracy: 0.9904 - val_loss: 1.4587 - val_accuracy: 0.6960\n",
            "Epoch 19/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0349 - accuracy: 0.9900 - val_loss: 1.5073 - val_accuracy: 0.7000\n",
            "Epoch 20/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 1.5013 - val_accuracy: 0.6970\n",
            "Epoch 21/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0332 - accuracy: 0.9902 - val_loss: 1.4739 - val_accuracy: 0.6990\n",
            "Epoch 22/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0257 - accuracy: 0.9927 - val_loss: 1.5151 - val_accuracy: 0.6980\n",
            "Epoch 23/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 1.5478 - val_accuracy: 0.7030\n",
            "Epoch 24/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 1.5244 - val_accuracy: 0.7005\n",
            "Epoch 25/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 1.5702 - val_accuracy: 0.7090\n",
            "Epoch 26/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 1.5314 - val_accuracy: 0.7185\n",
            "Epoch 27/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 1.6077 - val_accuracy: 0.7125\n",
            "Epoch 28/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 1.6221 - val_accuracy: 0.7065\n",
            "Epoch 29/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 1.6172 - val_accuracy: 0.7135\n",
            "Epoch 30/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 1.6194 - val_accuracy: 0.7070\n",
            "Epoch 31/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 1.6160 - val_accuracy: 0.7130\n",
            "Epoch 32/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 1.6386 - val_accuracy: 0.7085\n",
            "Epoch 33/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 1.6540 - val_accuracy: 0.7135\n",
            "Epoch 34/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 1.6812 - val_accuracy: 0.7085\n",
            "Epoch 35/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 1.6703 - val_accuracy: 0.7090\n",
            "Epoch 36/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 1.6755 - val_accuracy: 0.7090\n",
            "Epoch 37/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 1.6726 - val_accuracy: 0.7225\n",
            "Epoch 38/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0165 - accuracy: 0.9946 - val_loss: 1.6894 - val_accuracy: 0.7185\n",
            "Epoch 39/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 1.7389 - val_accuracy: 0.7195\n",
            "Epoch 40/80\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 1.6896 - val_accuracy: 0.7145\n",
            "Epoch 41/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 1.7438 - val_accuracy: 0.7305\n",
            "Epoch 42/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 1.7335 - val_accuracy: 0.7185\n",
            "Epoch 43/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 1.7049 - val_accuracy: 0.7255\n",
            "Epoch 44/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 1.7052 - val_accuracy: 0.7265\n",
            "Epoch 45/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 1.7456 - val_accuracy: 0.7250\n",
            "Epoch 46/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 1.7434 - val_accuracy: 0.7290\n",
            "Epoch 47/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 1.6731 - val_accuracy: 0.7325\n",
            "Epoch 48/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 1.6892 - val_accuracy: 0.7235\n",
            "Epoch 49/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 1.7275 - val_accuracy: 0.7330\n",
            "Epoch 50/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 1.7805 - val_accuracy: 0.7245\n",
            "Epoch 51/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 1.6649 - val_accuracy: 0.7225\n",
            "Epoch 52/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 1.7253 - val_accuracy: 0.7315\n",
            "Epoch 53/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 1.7189 - val_accuracy: 0.7280\n",
            "Epoch 54/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 1.7184 - val_accuracy: 0.7280\n",
            "Epoch 55/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 1.6966 - val_accuracy: 0.7380\n",
            "Epoch 56/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.7082 - val_accuracy: 0.7290\n",
            "Epoch 57/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 1.6931 - val_accuracy: 0.7350\n",
            "Epoch 58/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 1.6926 - val_accuracy: 0.7330\n",
            "Epoch 59/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.7355 - val_accuracy: 0.7365\n",
            "Epoch 60/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 1.7006 - val_accuracy: 0.7515\n",
            "Epoch 61/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.7135 - val_accuracy: 0.7475\n",
            "Epoch 62/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 1.7171 - val_accuracy: 0.7405\n",
            "Epoch 63/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 1.7176 - val_accuracy: 0.7375\n",
            "Epoch 64/80\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 1.7347 - val_accuracy: 0.7400\n",
            "Epoch 65/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 1.7461 - val_accuracy: 0.7465\n",
            "Epoch 66/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 1.7630 - val_accuracy: 0.7335\n",
            "Epoch 67/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 1.7529 - val_accuracy: 0.7305\n",
            "Epoch 68/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 1.7774 - val_accuracy: 0.7425\n",
            "Epoch 69/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.7304 - val_accuracy: 0.7395\n",
            "Epoch 70/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 1.7438 - val_accuracy: 0.7440\n",
            "Epoch 71/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 1.7938 - val_accuracy: 0.7455\n",
            "Epoch 72/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 1.8046 - val_accuracy: 0.7360\n",
            "Epoch 73/80\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 1.7306 - val_accuracy: 0.7465\n",
            "Epoch 74/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 1.6956 - val_accuracy: 0.7445\n",
            "Epoch 75/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0097 - accuracy: 0.9970 - val_loss: 1.7905 - val_accuracy: 0.7330\n",
            "Epoch 76/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 1.7343 - val_accuracy: 0.7450\n",
            "Epoch 77/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 1.7566 - val_accuracy: 0.7385\n",
            "Epoch 78/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.8225 - val_accuracy: 0.7440\n",
            "Epoch 79/80\n",
            "391/391 [==============================] - 57s 147ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 1.8019 - val_accuracy: 0.7475\n",
            "Epoch 80/80\n",
            "391/391 [==============================] - 58s 147ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 1.7727 - val_accuracy: 0.7490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Baseline vs yours: \",g_org_res[1]*100, yours[1]*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNCrCKZ1PbZ2",
        "outputId": "f9eebb61-7fb2-4fb9-dcdb-9930d49662e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline vs yours:  71.92000150680542 75.44999718666077\n"
          ]
        }
      ]
    }
  ]
}