{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[3]DNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqj3w7QFBo-Y",
        "outputId": "4629ff55-7050-41fa-ffb2-86377e1ea957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version:  2.8.2\n",
            "python version:  3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n",
            "numpy version:  1.21.6\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From <ipython-input-1-3109e1c8086c>:54: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "Model 0th accuracy: 86.94999814033508\n",
            "Model 1th accuracy: 86.94999814033508\n",
            "Model 2th accuracy: 86.94999814033508\n",
            "Baseline (average) accuracy: 86.94999814033508\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model 0th accuracy: 86.72000169754028\n",
            "Model 1th accuracy: 86.72000169754028\n",
            "Model 2th accuracy: 86.72000169754028\n",
            "Proposed (average) accuracy: 86.72000169754028\n",
            "Baseline vs. Mine: 86.94999814033508 vs. 86.72000169754028 under GPU True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "####*IMPORANT*: Have to do this line *before* importing tensorflow\n",
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD,Adam,Adagrad,RMSprop\n",
        "print(\"tensorflow version: \", tf.__version__)\n",
        "print(\"python version: \", sys.version)\n",
        "print(\"numpy version: \", np.__version__)\n",
        "\n",
        "### WARN: Must have ###\n",
        "# to make this notebook's output stable across runs\n",
        "def reset_random_seeds():\n",
        "   os.environ['PYTHONHASHSEED']=str(1)\n",
        "   tf.random.set_seed(1)\n",
        "   np.random.seed(1)\n",
        "   random.seed(1)\n",
        "   os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "   \n",
        "reset_random_seeds()\n",
        "\n",
        "# fashion MNIST 읽어 와서 신경망에 입력할 형태로 변환\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(60000,784)\n",
        "x_test = x_test.reshape(10000,784)\n",
        "x_train=x_train.astype(np.float32)/255.0\n",
        "x_test=x_test.astype(np.float32)/255.0\n",
        "y_train=tf.keras.utils.to_categorical(y_train,10)\n",
        "y_test=tf.keras.utils.to_categorical(y_test,10)\n",
        "\n",
        "# 모델을 설계해주는 함수(모델을 나타내는 객체 model을 반환)\n",
        "def run_model(x_train, y_train):    \n",
        "    ####*IMPORANT*: Have to do this below line *every* re-run modeling & training\n",
        "    reset_random_seeds()\n",
        "    model=Sequential()\n",
        "    model.add(Dense(512,activation='relu',input_shape=(784,)))\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, batch_size=256, epochs=5, verbose=0)\n",
        "    return model\n",
        "\n",
        "### Update: 22.04.01\n",
        "n_of_models = 3\n",
        "acc = 0\n",
        "models = []\n",
        "if tf.test.is_gpu_available():\n",
        "  for n in range (0, n_of_models):\n",
        "    models.append(run_model(x_train, y_train))\n",
        "    acc += models[n].evaluate(x_test,y_test,verbose=0)[1]*100\n",
        "    print('Model {}th accuracy: {}'.format(n, models[n].evaluate(x_test,y_test,verbose=0)[1]*100))\n",
        "  acc /= n_of_models\n",
        "else:\n",
        "  n_of_models = 1\n",
        "  n = 0\n",
        "  models.append(run_model(x_train, y_train))\n",
        "  print('Model {}th accuracy: {}'.format(n, models[n].evaluate(x_test,y_test,verbose=0)[1]*100))\n",
        "  acc =  models[n].evaluate(x_test,y_test,verbose=0)[1]*100\n",
        "\n",
        "g_org_model_acc = acc\n",
        "print('Baseline (average) accuracy: {}'.format(acc))\n",
        "\n",
        "models[0].summary()\n",
        "\n",
        "# My Model\n",
        "def run_proposed_model(x_train, y_train):  \n",
        "    reset_random_seeds()  \n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024,activation='relu',input_shape=(784,))) #number of nodes: 512 -> 1024\n",
        "    model.add(Dense(512,activation='relu'))\n",
        "    model.add(Dense(512,activation='relu')) #add layer\n",
        "    model.add(Dense(10,activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    model.fit(x_train, y_train, batch_size=256, epochs=5, verbose=0)\n",
        "    return model\n",
        "\n",
        "n_of_models = 3\n",
        "acc = 0\n",
        "pro_models = []\n",
        "if tf.test.is_gpu_available():\n",
        "  for n in range (0, n_of_models):\n",
        "    pro_models.append(run_proposed_model(x_train, y_train))\n",
        "    acc += pro_models[n].evaluate(x_test,y_test,verbose=0)[1]*100 # verbose=1 when you want to see the progress\n",
        "    print('Model {}th accuracy: {}'.format(n, \n",
        "                                           pro_models[n].evaluate(x_test,y_test,verbose=0)[1]*100))\n",
        "  acc /= n_of_models\n",
        "else:\n",
        "  n_of_models = 1\n",
        "  n = 0\n",
        "  pro_models.append(run_proposed_model(x_train, y_train))\n",
        "  print('Model {}th accuracy: {}'.format(n, \n",
        "                                         pro_models[n].evaluate(x_test,y_test,verbose=0)[1]*100))\n",
        "  acc =  pro_models[n].evaluate(x_test,y_test,verbose=0)[1]*100 # verbose=1 when you want to see the progress\n",
        "\n",
        "g_pro_model_acc = acc\n",
        "print('Proposed (average) accuracy: {}'.format(acc))\n",
        "  \n",
        "# baseline vs Mine\n",
        "print('Baseline vs. Mine: {} vs. {} under GPU {}'.format(g_org_model_acc, \n",
        "                                                         g_pro_model_acc, \n",
        "                                                         tf.test.is_gpu_available()))"
      ]
    }
  ]
}